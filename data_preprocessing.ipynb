{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PIL\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import chitra\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from chitra.image import Chitra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(typ):\n",
    "\n",
    "    \"\"\"Load image data and join with annotation information.\"\"\"\n",
    "\n",
    "    df_annotation = pd.read_csv(f\"data/{typ}/_annotations.csv\")\n",
    "    df_img = pd.DataFrame()\n",
    "\n",
    "    base_dir = rf'data/{typ}/*.jpg'\n",
    "    files = glob(base_dir)\n",
    "\n",
    "    imgs = []\n",
    "    for i in files:\n",
    "        imgs.append(plt.imread(i))\n",
    "\n",
    "    files = [re.sub(f'data/{typ}/', '', i) for i in files]\n",
    "\n",
    "    df_img['filename'] = files\n",
    "    df_img['image'] = imgs\n",
    "    df_train = pd.merge(df_annotation, df_img, on='filename')\n",
    "    return df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_data('train')\n",
    "#df_valid = load_data('valid')\n",
    "#df_test = load_data('test')\n",
    "\n",
    "print(df_train.info())\n",
    "#print(df_valid.info())\n",
    "#print(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to pickle:\n",
    "#df_train.to_pickle('data/chess_new.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ranges of bounding boxes\n",
    "#df_train[['xmin', 'ymin', 'xmax', 'ymax']].agg(['max', 'min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Display sample image with annotation\n",
    "\n",
    "sample_img = df_train.iloc[1111,:] #4801\n",
    "\n",
    "\n",
    "figsize = sample_img['width'] / float(100), sample_img['height']/ float(100)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "#new_width = sample_img['width'] / 6.4\n",
    "#new_height = sample_img['height'] / 4.8\n",
    "\n",
    "#ax.axis('off')\n",
    "ax.imshow(sample_img['image'])\n",
    "rect = patches.Rectangle((sample_img['xmin'], sample_img['ymin']), \n",
    "                         sample_img['xmax']-sample_img['xmin'], \n",
    "                         sample_img['ymax']-sample_img['ymin'],\n",
    "                         edgecolor='red',\n",
    "                         facecolor='none',\n",
    "                         linewidth=3,\n",
    "                         )\n",
    "\n",
    "ax.add_patch(rect)\n",
    "annot_height = sample_img['ymin'] + (sample_img['ymax']-sample_img['ymin']) + 20\n",
    "ax.annotate(sample_img['class'], (sample_img['xmin'], annot_height), color='red',\n",
    "            size=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some annotations are incorrect (e.g. axes transposed). Manually check if annotations are correct in `check_annotations.ipynb`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cheked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add togehther annotations\n",
    "annot_1 = pd.read_csv('data/checked_annot/top_184_anot.csv')\n",
    "annot_2 = pd.read_csv('data/checked_annot/bottom_annot.csv')\n",
    "annot_3 = pd.read_csv('data/checked_annot/bottom_annot_1602_downwards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1025 entries, 0 to 371\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    1025 non-null   int64 \n",
      " 1   filename      1025 non-null   object\n",
      " 2   correct_anot  1015 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 32.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate sheets\n",
    "annot_total = pd.concat([annot_1, annot_2, annot_3])\n",
    "annot_total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for correctly annotated\n",
    "annot_correct = annot_total[annot_total['correct_anot'] == 'y']\n",
    "\n",
    "# get length of correctly annotated:\n",
    "annot_img_list = list(annot_correct['filename'].unique())\n",
    "print(len(annot_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new dataset\n",
    "chess_df = df_train[df_train['filename'].isin(annot_img_list)]\n",
    "#print(chess_df.info())\n",
    "\n",
    "# Check unique pictures\n",
    "chess_df['filename'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to csv\n",
    "#chess_df.to_pickle('data/chess_new.p')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that `image` is a `Chitra` object:\n",
    "\n",
    "* Get ndarray of image with `image.numpy()`\n",
    "* Get resized bounding box xmin, ymin with `image.bboxes[0][0]`\n",
    "* Get resized bounding box xmax, ymax with `image.bboxes[0][1]`\n",
    "* Get resized bounding box label with `image.bboxes[0].label`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod data:\n",
    "chess_df = pd.read_pickle('data/chess_new.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample image with chitra:\n",
    "\n",
    "import chitra\n",
    "from chitra.image import Chitra\n",
    "\n",
    "tryout = chess_df.iloc[7]\n",
    "\n",
    "ymin = tryout['ymin']\n",
    "ymax = tryout['ymax']\n",
    "xmin = tryout['xmin']\n",
    "xmax = tryout['xmax']\n",
    "\n",
    "label = tryout['class']\n",
    "\n",
    "bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "filename = tryout['filename']\n",
    "\n",
    "img_path = f'data/train/{filename}'\n",
    "image = Chitra(img_path, bboxes=bbox, labels=label, box_format= 'BoundingBoxes.CORNER')\n",
    "image.resize_image_with_bbox((224, 224))\n",
    "\n",
    "figsize = tryout['width'] / float(100), tryout['height']/ float(100)\n",
    "\n",
    "#plt.figure(figsize=figsize)\n",
    "plt.imshow(image.draw_boxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(samp, resize = (224, 224)):\n",
    "    \n",
    "    \"\"\"Function to convert one row of chess df to dictionary with resized information.\"\"\"\n",
    "\n",
    "    bbox = [samp['xmin'], samp['ymin'], samp['xmax'], samp['ymax']]\n",
    "    \n",
    "    filename = samp['filename']\n",
    "    img_path = f'data/train/{filename}'\n",
    "    \n",
    "    image = Chitra(img_path, bboxes=bbox, labels=samp['class'], box_format='BoundingBoxes.CORNER')\n",
    "    image.resize_image_with_bbox(resize)\n",
    "\n",
    "    return {'filename': filename, \n",
    "            'width': image.shape[0], \n",
    "            'height': image.shape[1], \n",
    "            'class': image.bboxes[0].label, \n",
    "            'xmin': image.bboxes[0][0][0], \n",
    "            'ymin': image.bboxes[0][0][1], \n",
    "            'xmax' : image.bboxes[0][1][0], \n",
    "            'ymax': image.bboxes[0][1][1], \n",
    "            'image': image.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dataset and append resized images:\n",
    "\n",
    "df_chess_resized= pd.DataFrame()\n",
    "\n",
    "for i in range(chess_df.shape[0]):\n",
    "    \n",
    "    df_add = pd.DataFrame.from_dict(resize_images(chess_df.iloc[i]), orient='index').T\n",
    "    df_chess_resized = pd.concat([df_chess_resized, df_add], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_chess_resized.to_pickle('data/chess_resized.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chesspiece-Detection-KloNB-iQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed2134023738693953f36c3bef60cd2c1ec1a5b30f59b14e0edb653ce3bbd869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
