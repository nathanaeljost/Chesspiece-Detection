{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import PIL\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Note:</font> Code loosely inspired by [this](https://towardsdatascience.com/board-game-image-recognition-using-neural-networks-116fc876dafa); see also [Github link](https://github.com/andrewleeunderwood/project_MYM)\n",
    "\n",
    "<font color='red'>--> Does not work yet, only copied from the link above</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>black-bishop</td>\n",
       "      <td>45.422222</td>\n",
       "      <td>107.333328</td>\n",
       "      <td>64.296295</td>\n",
       "      <td>121.17778</td>\n",
       "      <td>[[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>black-bishop</td>\n",
       "      <td>46.874073</td>\n",
       "      <td>70.466667</td>\n",
       "      <td>67.40741</td>\n",
       "      <td>85.08889</td>\n",
       "      <td>[[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>black-king</td>\n",
       "      <td>13.066667</td>\n",
       "      <td>123.82222</td>\n",
       "      <td>42.725925</td>\n",
       "      <td>136.422226</td>\n",
       "      <td>[[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>black-king</td>\n",
       "      <td>10.162963</td>\n",
       "      <td>158.044449</td>\n",
       "      <td>42.725925</td>\n",
       "      <td>179.511108</td>\n",
       "      <td>[[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>black-king</td>\n",
       "      <td>162.607407</td>\n",
       "      <td>175.622223</td>\n",
       "      <td>194.340729</td>\n",
       "      <td>202.533325</td>\n",
       "      <td>[[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename width height  \\\n",
       "13  IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...   224    224   \n",
       "14  IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...   224    224   \n",
       "15  IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...   224    224   \n",
       "16  IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...   224    224   \n",
       "17  IMG_20220815_212205_DRO_jpg.rf.006398adca061fc...   224    224   \n",
       "\n",
       "           class        xmin        ymin        xmax        ymax  \\\n",
       "13  black-bishop   45.422222  107.333328   64.296295   121.17778   \n",
       "14  black-bishop   46.874073   70.466667    67.40741    85.08889   \n",
       "15    black-king   13.066667   123.82222   42.725925  136.422226   \n",
       "16    black-king   10.162963  158.044449   42.725925  179.511108   \n",
       "17    black-king  162.607407  175.622223  194.340729  202.533325   \n",
       "\n",
       "                                                image  \n",
       "13  [[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...  \n",
       "14  [[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...  \n",
       "15  [[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...  \n",
       "16  [[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...  \n",
       "17  [[[15, 13, 16], [14, 12, 15], [11, 9, 12], [13...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laod data:\n",
    "train_small_df = pd.read_pickle('data/final_data/train/chess_train_df.p')\n",
    "train_small_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2612 images belonging to 12 classes.\n",
      "Found 301 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "folder = 'data/final_data'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        #rotation_range=5,\n",
    "        rescale=1./255,\n",
    "        #horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    folder + '/train/train_flow',\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    shuffle=True)\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    folder + '/test/test_flow',\n",
    "    target_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3)) \n",
    " \n",
    "# Freeze convolutional layers from VGG16\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Establish new fully connected block\n",
    "x = base_model.output\n",
    "x = Flatten()(x) \n",
    "x = Dense(500, activation='relu')(x) \n",
    "x = Dense(500, activation='relu')(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "# This is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    epochs = 10\n",
    "    history = model.fit(\n",
    "        train_gen, \n",
    "        epochs=epochs,\n",
    "        #verbose = 1,\n",
    "        validation_data=test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chesspiece-Detection-KloNB-iQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed2134023738693953f36c3bef60cd2c1ec1a5b30f59b14e0edb653ce3bbd869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
